{
    "BLSTM": {
        "_type": "BLSTM",
        "allow-none": false,
        "batch_size": [
            64,
            128,
            256
        ],
        "dropout": [
            0.0,
            0.1,
            0.2
        ],
        "epochs": 50,
        "features": [],
        "hidden_layer_size": [
            64,
            128,
            256
        ],
        "learning_rate": [
            0.001,
            0.01,
            0.1
        ],
        "model-file": "./model",
        "preprocessors": [],
        "save-training": null,
        "sequence_length": 4,
        "step": 4,
        "trainon": 1.0,
        "verbose": 1
    }
}
